# ml_bsns

## Шаг 1
В файле features.py (который вы создавали в 5 уроке прошлого модуля) с помощью цикла сделайте бесконечной отправку вектора признаков и ответов. Добавьте некоторую задержку после каждой итерации, чтобы можно было отслеживать происходящее. Это можно сделать с помощью функции sleep из модуля time (он встроен в Python и не нуждается в установке).

Например, следующий код позволяет «усыпить» программу на десять секунд:

import time
time.sleep(10)
Далее добавьте в каждое сообщение уникальный идентификатор. Чтобы сформировать идентификаторы, можно воспользоваться текущей датой в формате timestamp. Для этого можно применить встроенный в стандартную библиотеку Python модуль datetime:

from datetime import datetime
message_id = datetime.timestamp(datetime.now())
Далее этот идентификатор можно добавить в передаваемые сообщения перед сериализацией. Например, сообщение, передаваемое в очередь y_true, может выглядеть следующим образом:

message_y_true = {
    'id': message_id,
    'body': y[random_row]
}
Обратите внимание, что теперь сообщения передаются в формате словарей — не забудьте перевести в этот формат и другие микросервисы.

Важно, чтобы признакам, соответствующим им истинным ответам и предсказаниям были присвоены одинаковые ID.

## Шаг 2
Далее добавьте в ваше приложение логирование метрик.

В папке logs/ создайте файл metric_log.csv. В нём будет храниться таблица со следующими столбцами: id, y_true, y_pred, absolute_error.

Запишите в файл metric.csv имена столбцов, чтобы инициализировать таблицу (обратите внимание, что в CSV-файле элементы таблицы записываются без пробелов):

Файл ./logs/metric_log.csv

id,y_true,y_pred,absolute_error
Измените файл metric.py, который вы подготовили в этом модуле, таким образом, чтобы скрипт в режиме реального времени записывал в файл metric_log.csv идентификаторы сообщения, истинные метки, предсказания, а также абсолютные ошибки между истиной и прогнозом.

Примечание. Рассчитывайте абсолютные ошибки по следующей формуле:


Важно! Так как сообщения с истинными метками и предсказаниями модели поступают в сервис metric из двух разных очередей, которые работают в асинхронном режиме, для вычисления абсолютных ошибок вам необходимо будет придумать способ сохранения приходящих сообщений перед расчётом абсолютной ошибки.

Например, вы можете записывать приходящие сообщения в соответствующие столбцы DataFrame, а когда в таблице появятся и y_true, и y_pred, соответствующие заданному идентификатору — вычислять абсолютную ошибку модели. Также вы можете придумать свой вариант обработки.

После каждой итерации сервиса features в файле metric_log.csv должна появляться новая запись с соответствующим идентификатором, истинным ответом, предсказанием и ошибкой. Ниже представлен пример содержания этого файла после пяти итераций сервиса features:

Файл ./logs/metric_log.csv

id,y_true,y_pred,absolute_error
1669147134.196809,295.0,221.77392889122234,73.22607110877766
1669147136.824343,153.0,118.44344405446542,34.55655594553458
1669147141.035324,189.0,204.06083656673704,15.060836566737038
1669147148.42061,173.0,200.44085356158348,27.44085356158348
1669147162.280003,154.0,159.34185386962795,5.341853869627954


## Шаг 3
Добавьте к вашей архитектуре ещё один сервис — plot. Скрипт с его кодом назовите plot.py. Данный сервис должен в бесконечном цикле читать таблицу metric_log.csv и строить график распределения (гистограмму) абсолютных ошибок. График должен записываться в файл logs/error_distribution.png.

Создайте для нового сервиса Dockerfile, указав в нём инструкции по сборке образа контейнера. Не забудьте добавить все необходимые зависимости, указав их в файле requirements.txt.

После создания самого скрипта микросервиса и инструкций по его сборке добавьте инструкции по его запуску в compose-файл. Продумайте, от каких сервисов зависит сервис plot. Помните, что при запуске сервиса plot необходимо связать локальную директорию logs/ и рабочую директорию контейнера.

В результате работы сервиса в вашей локальной директории logs должен появиться файл error_distribution.png с гистограммой. Гистограмма должна обновляться с каждой итерацией запуска сервиса features.